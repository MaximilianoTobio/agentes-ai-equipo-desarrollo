# üìä M√©tricas, Monitoreo y Observabilidad

> **Ubicaci√≥n sugerida:** `/docs/v2/08_metricas_y_monitoreo.md`\
> **Prop√≥sito:** Documentar c√≥mo se miden, visualizan y monitorean las
> m√©tricas t√©cnicas, XP y de costos del sistema multi-agente.\
> **Enfoque:** observabilidad integral, KPIs accionables y alertas
> preventivas.

------------------------------------------------------------------------

## 1. Filosof√≠a de Observabilidad

> "No se puede mejorar lo que no se mide."

La observabilidad del sistema busca m√°s que recolectar datos:\
permite **entender el comportamiento de los agentes, anticipar errores y
optimizar recursos.**

El sistema combina m√©tricas (Prometheus), trazas (Jaeger) y dashboards
(Grafana) para obtener una visi√≥n completa de la salud t√©cnica y del
rendimiento XP.

------------------------------------------------------------------------

## 2. Arquitectura de Monitoreo

``` mermaid
flowchart LR
    A[Orchestrator] -->|Exposici√≥n /metrics| P[Prometheus]
    B[Agents] -->|M√©tricas internas| P
    P --> G[Grafana Dashboards]
    A --> J[Jaeger Traces]
    B --> J
    G --> U[Usuario / DevOps]
```

### Componentes

  ---------------------------------------------------------------------------
  Servicio                       Rol              Ejemplo
  ------------------------------ ---------------- ---------------------------
  **Prometheus**                 Recolecta        `/metrics` endpoint
                                 m√©tricas         
                                 expuestas por    
                                 agentes y        
                                 orquestador      

  **Grafana**                    Visualiza        Lead time, TDD, latencia
                                 dashboards       
                                 t√©cnicos y XP    

  **Jaeger**                     Rastrea trazas   Issue ‚Üí Merge completo
                                 distribuidas     

  **Alertmanager**               Env√≠a alertas a  Tokens, fallos CI, colas
                                 Slack/Telegram   largas
  ---------------------------------------------------------------------------

------------------------------------------------------------------------

## 3. Tipos de M√©tricas

### 3.1 T√©cnicas (DevOps)

  ---------------------------------------------------------------------------------
  M√©trica                          Descripci√≥n                   Fuente
  -------------------------------- ----------------------------- ------------------
  `orchestrator_up`                Estado del servicio           Orchestrator

  `api_request_duration_seconds`   Latencia de endpoints         FastAPI Middleware

  `queue_length`                   Longitud de Redis Streams     Redis Exporter

  `messages_lost_total`            Mensajes fallidos o           Orchestrator
                                   duplicados                    

  `ci_failures_total`              Fallos en pipelines           GitHub Actions

  `uptime_ratio`                   \% disponibilidad servicio    Prometheus
  ---------------------------------------------------------------------------------

### 3.2 XP / Desarrollo

  -------------------------------------------------------------------------
  M√©trica                  Descripci√≥n                   Origen
  ------------------------ ----------------------------- ------------------
  `tdd_compliance_rate`    \% de PRs con tests previos   Orchestrator

  `coverage_avg`           Cobertura promedio            QAAgent

  `pair_success_rate`      √âxito de sesiones             PairCoordinator
                           Driver/Navigator              

  `refactors_per_sprint`   Refactors ejecutados          RefactorAgent

  `tech_debt_ratio`        Deuda t√©cnica medida          SonarQube

  `lead_time_avg_hours`    Tiempo issue ‚Üí merge          DB Query
  -------------------------------------------------------------------------

### 3.3 Costos / Eficiencia

  -----------------------------------------------------------------------------
  M√©trica                    Descripci√≥n                   Fuente
  -------------------------- ----------------------------- --------------------
  `token_usage_total`        Tokens consumidos por sprint  Orchestrator

  `token_budget_remaining`   Presupuesto restante          TokenBudgetManager

  `llm_cache_hit_rate`       Eficiencia del cach√©          Redis Exporter

  `cost_per_pr_usd`          Costo promedio por PR         Dashboard

  `cache_savings_percent`    Tokens ahorrados por caching  Prometheus Rule
  -----------------------------------------------------------------------------

------------------------------------------------------------------------

## 4. Dashboards Clave en Grafana

### 4.1 **üìà Dashboard "System Health"**

-   Uptime del orquestador (gauge)
-   Latencia API (P50/P95/P99)
-   Queue Length (gr√°fico en tiempo real)
-   CPU/RAM de agentes

### 4.2 **üß™ Dashboard "XP Metrics"**

-   TDD compliance rate
-   Test coverage
-   Pair sessions completadas
-   Refactors por sprint
-   DoD pass/fail ratio

### 4.3 **üí∞ Dashboard "Token & Cost Control"**

-   Tokens usados por agente/sprint
-   Cache hit rate
-   Cost per PR (USD)
-   Alertas de budget
-   Savings acumulado (%)

### 4.4 **üß≠ Dashboard "Lead Time & Flow Efficiency"**

-   Lead time promedio por tipo de issue
-   Cycle time (creaci√≥n ‚Üí merge)
-   Throughput por sprint
-   Flow efficiency (% de trabajo activo vs espera)

------------------------------------------------------------------------

## 5. Alertas Autom√°ticas

### 5.1 Ejemplos de Reglas Prometheus

``` yaml
groups:
  - name: orchestrator.rules
    rules:
      - alert: OrchestratorDown
        expr: up{job="orchestrator"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Orchestrator ca√≠do"
          description: "El servicio principal no responde."

      - alert: QueueTooLong
        expr: queue_length > 100
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Redis Streams congestionado"
          description: "Hay m√°s de 100 tareas pendientes."

      - alert: TokenBudgetCritical
        expr: token_budget_remaining < 0.1
        labels:
          severity: critical
        annotations:
          summary: "Presupuesto de tokens casi agotado"
          description: "El sistema debe reducir uso de modelos LLM."
```

### 5.2 Canales de Alerta

-   **Slack / Telegram** ‚Üí notificaciones instant√°neas.\
-   **Email / Ops dashboard** ‚Üí informes diarios.\
-   **Webhook** ‚Üí integraci√≥n con n8n o monitor interno.

------------------------------------------------------------------------

## 6. Trazabilidad con Jaeger

Cada tarea (issue ‚Üí PR) genera una **trace distribuida** con spans: 1.
Webhook recibido (GitHub)\
2. Creaci√≥n de tarea (Orchestrator)\
3. DevAgent ‚Üí QAAgent ‚Üí ReviewAgent\
4. Merge final / audit trail

Permite: - Medir latencia por etapa.\
- Detectar cuellos de botella.\
- Trazar incidentes end-to-end.

Ejemplo de nombre de trace:\
`TRACE[feat:add_login:T-104]`

------------------------------------------------------------------------

## 7. M√©tricas de Negocio y ROI

A nivel estrat√©gico, las m√©tricas t√©cnicas se combinan con indicadores
de productividad:

  ------------------------------------------------------------------------
  KPI               Descripci√≥n                          Meta
  ----------------- ------------------------------------ -----------------
  **Costo / PR**    USD promedio por PR generado         \< \$8

  **ROI vs          Ahorro total en tokens + horas       \> 400%
  desarrollo                                             
  manual**                                               

  **Lead time**     Tiempo issue ‚Üí merge                 \< 4h

  **MTTR**          Tiempo medio de resoluci√≥n de fallos \< 10 min

  **Deuda t√©cnica** \% detectado por SonarQube           \< 5%
  ------------------------------------------------------------------------

------------------------------------------------------------------------

## 8. Pol√≠tica de M√©tricas y Reporting

### 8.1 Recolecci√≥n continua

Todas las m√©tricas se exponen en `/metrics` y se actualizan cada 30s.

### 8.2 Retenci√≥n

-   Prometheus: 30 d√≠as (rotaci√≥n).\
-   Postgres (XP/negocio): hist√≥rico completo (con particiones
    mensuales).

### 8.3 Reporting peri√≥dico

-   **Semanal:** m√©tricas XP (DoD, refactors, TDD).\
-   **Mensual:** m√©tricas financieras (tokens, costos, ROI).\
-   **Incidentes:** reportes post-mortem autom√°ticos (ver Anexo B2).

------------------------------------------------------------------------

## 9. Interpretaci√≥n de KPIs

### 9.1 "Sem√°foro XP"

  Color   Estado      Significado
  ------- ----------- ----------------------------
  üü¢      Saludable   Dentro de umbrales
  üü°      En riesgo   Requiere ajuste operativo
  üî¥      Cr√≠tico     Acci√≥n inmediata requerida

### 9.2 Ejemplo de an√°lisis

-   **QueueLength alto + TDD rate bajo:** falta capacidad de DevAgent.\
-   **Token usage alto + Cache hit bajo:** prompts redundantes o mala
    clasificaci√≥n.\
-   **Lead time alto pero tests ok:** cuello en ReviewAgent.

------------------------------------------------------------------------

## 10. Conclusi√≥n

El sistema no solo ejecuta tareas: **se mide a s√≠ mismo**.\
Cada agente, pipeline y decisi√≥n queda reflejada en m√©tricas
cuantificables, lo que permite una evoluci√≥n basada en evidencia.

> "Lo que no se mide, se repite. Lo que se mide, se mejora."

------------------------------------------------------------------------

**Versi√≥n:** v2.0 --- Octubre 2025\
**Autor:** Equipo de Ingenier√≠a -- Proyecto Agentes AI
